{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from models.vgg import VGG\n",
    "from models.densenet import DenseNet3\n",
    "from models.wideresnet import WideResNet\n",
    "from utils.ood_metrics import tpr95, detection\n",
    "from utils.datasets import GaussianNoise, UniformNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ind_dataset = cifar10\n",
    "ood_dataset = tinyImageNet_resize\n",
    "model = vgg13\n",
    "process = confidence\n",
    "'''\n",
    "batch_size =128\n",
    "T = 1000.\n",
    "epsilon = 0.001\n",
    "filename = 'checkpoints/cifar10_vgg13_budget_0.3_seed_0'\n",
    "validation = False\n",
    "cudnn.benchmark = True  # Should make training should go faster for large models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規化の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in-distributionはCIFAR10<br>out-of-distributionはImagenet_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "ind_dataset = datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "ood_dataset = datasets.ImageFolder(root='data/Imagenet_resize', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.ImageFolder(root='data/Imagenet_resize', transform=transforms.Compose([transforms.ToTensor()]))\n",
    "img, lab = test[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet_resizeの画像を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f997a5ec710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def imshow(img):\n",
    "    # unnormalize [-1, 1] => [0, 1]\n",
    "    #img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    # [c, h, w] => [h, w, c]\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "imshow(make_grid(img))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データローダー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_loader = torch.utils.data.DataLoader(\n",
    "                                         dataset=ind_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         pin_memory=True,\n",
    "                                         num_workers=2)\n",
    "\n",
    "ood_loader = torch.utils.data.DataLoader(\n",
    "                                         dataset=ood_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         pin_memory=True,\n",
    "                                         num_workers=2)\n",
    "\n",
    "# Use remaining samples for test evaluation\n",
    "ood_loader.dataset.imgs = ood_loader.dataset.imgs[1000:]\n",
    "ood_loader.dataset.__len__ = len(ood_loader.dataset.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルはVGG13＋学習した重みをロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU(inplace)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU(inplace)\n",
       "    (31): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (33): ReLU(inplace)\n",
       "    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (35): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (confidence): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = VGG(vgg_name='VGG13', num_classes=num_classes).cuda()\n",
    "model_dict = cnn.state_dict()\n",
    "pretrained_dict = torch.load(filename + '.pt')\n",
    "cnn.load_state_dict(pretrained_dict)\n",
    "cnn = cnn.cuda()\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(ind_loader)\n",
    "images, labels = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Variable(images, requires_grad=True).cuda()\n",
    "prediction, confidence = cnn(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takano/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "# 最終層の活性化\n",
    "pred_original = F.softmax(prediction, dim=-1)\n",
    "confidence = F.sigmoid(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8413],\n",
       "        [0.7855],\n",
       "        [0.4223],\n",
       "        [0.3229],\n",
       "        [0.9504],\n",
       "        [0.7313],\n",
       "        [0.7509],\n",
       "        [0.6937],\n",
       "        [0.8718],\n",
       "        [0.8501],\n",
       "        [0.8419],\n",
       "        [0.9657],\n",
       "        [0.7512],\n",
       "        [0.9822],\n",
       "        [0.9834],\n",
       "        [0.2472],\n",
       "        [0.9865],\n",
       "        [0.7856],\n",
       "        [0.9376],\n",
       "        [0.8467],\n",
       "        [0.1475],\n",
       "        [0.2287],\n",
       "        [0.7625],\n",
       "        [0.9601],\n",
       "        [0.4784],\n",
       "        [0.6039],\n",
       "        [0.6829],\n",
       "        [0.9738],\n",
       "        [0.9062],\n",
       "        [0.9366],\n",
       "        [0.8901],\n",
       "        [0.9389],\n",
       "        [0.3777],\n",
       "        [0.7024],\n",
       "        [0.9798],\n",
       "        [0.2202],\n",
       "        [0.5849],\n",
       "        [0.7535],\n",
       "        [0.9286],\n",
       "        [0.9945],\n",
       "        [0.9719],\n",
       "        [0.9069],\n",
       "        [0.2055],\n",
       "        [0.9007],\n",
       "        [0.9588],\n",
       "        [0.9802],\n",
       "        [0.3751],\n",
       "        [0.1861],\n",
       "        [0.9289],\n",
       "        [0.4453],\n",
       "        [0.9247],\n",
       "        [0.8737],\n",
       "        [0.2837],\n",
       "        [0.5722],\n",
       "        [0.9119],\n",
       "        [0.9708],\n",
       "        [0.7056],\n",
       "        [0.4098],\n",
       "        [0.2590],\n",
       "        [0.2389],\n",
       "        [0.9773],\n",
       "        [0.4460],\n",
       "        [0.7240],\n",
       "        [0.2333],\n",
       "        [0.7029],\n",
       "        [0.6119],\n",
       "        [0.8774],\n",
       "        [0.9431],\n",
       "        [0.4124],\n",
       "        [0.4886],\n",
       "        [0.1877],\n",
       "        [0.4452],\n",
       "        [0.6262],\n",
       "        [0.9823],\n",
       "        [0.4635],\n",
       "        [0.9492],\n",
       "        [0.9028],\n",
       "        [0.9343],\n",
       "        [0.1275],\n",
       "        [0.8636],\n",
       "        [0.9394],\n",
       "        [0.5707],\n",
       "        [0.9896],\n",
       "        [0.8516],\n",
       "        [0.6589],\n",
       "        [0.1427],\n",
       "        [0.3436],\n",
       "        [0.4723],\n",
       "        [0.9791],\n",
       "        [0.8443],\n",
       "        [0.9746],\n",
       "        [0.3082],\n",
       "        [0.9398],\n",
       "        [0.9888],\n",
       "        [0.7867],\n",
       "        [0.5611],\n",
       "        [0.6133],\n",
       "        [0.2216],\n",
       "        [0.7310],\n",
       "        [0.8226],\n",
       "        [0.4127],\n",
       "        [0.7344],\n",
       "        [0.9775],\n",
       "        [0.8927],\n",
       "        [0.9902],\n",
       "        [0.9819],\n",
       "        [0.7064],\n",
       "        [0.9727],\n",
       "        [0.7107],\n",
       "        [0.9194],\n",
       "        [0.5488],\n",
       "        [0.9287],\n",
       "        [0.1849],\n",
       "        [0.9170],\n",
       "        [0.8172],\n",
       "        [0.4231],\n",
       "        [0.8697],\n",
       "        [0.3881],\n",
       "        [0.2399],\n",
       "        [0.4931],\n",
       "        [0.8016],\n",
       "        [0.5586],\n",
       "        [0.9276],\n",
       "        [0.9831],\n",
       "        [0.7249],\n",
       "        [0.2405],\n",
       "        [0.4668],\n",
       "        [0.5413]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clampメソッドで数値を範囲内に収める\n",
    "eps = 1e-12\n",
    "pred_original = torch.clamp(pred_original, 0. + eps, 1. - eps)\n",
    "confidence = torch.clamp(confidence, 0. + eps, 1. - eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8413],\n",
       "        [0.7855],\n",
       "        [0.4223],\n",
       "        [0.3229],\n",
       "        [0.9504],\n",
       "        [0.7313],\n",
       "        [0.7509],\n",
       "        [0.6937],\n",
       "        [0.8718],\n",
       "        [0.8501],\n",
       "        [0.8419],\n",
       "        [0.9657],\n",
       "        [0.7512],\n",
       "        [0.9822],\n",
       "        [0.9834],\n",
       "        [0.2472],\n",
       "        [0.9865],\n",
       "        [0.7856],\n",
       "        [0.9376],\n",
       "        [0.8467],\n",
       "        [0.1475],\n",
       "        [0.2287],\n",
       "        [0.7625],\n",
       "        [0.9601],\n",
       "        [0.4784],\n",
       "        [0.6039],\n",
       "        [0.6829],\n",
       "        [0.9738],\n",
       "        [0.9062],\n",
       "        [0.9366],\n",
       "        [0.8901],\n",
       "        [0.9389],\n",
       "        [0.3777],\n",
       "        [0.7024],\n",
       "        [0.9798],\n",
       "        [0.2202],\n",
       "        [0.5849],\n",
       "        [0.7535],\n",
       "        [0.9286],\n",
       "        [0.9945],\n",
       "        [0.9719],\n",
       "        [0.9069],\n",
       "        [0.2055],\n",
       "        [0.9007],\n",
       "        [0.9588],\n",
       "        [0.9802],\n",
       "        [0.3751],\n",
       "        [0.1861],\n",
       "        [0.9289],\n",
       "        [0.4453],\n",
       "        [0.9247],\n",
       "        [0.8737],\n",
       "        [0.2837],\n",
       "        [0.5722],\n",
       "        [0.9119],\n",
       "        [0.9708],\n",
       "        [0.7056],\n",
       "        [0.4098],\n",
       "        [0.2590],\n",
       "        [0.2389],\n",
       "        [0.9773],\n",
       "        [0.4460],\n",
       "        [0.7240],\n",
       "        [0.2333],\n",
       "        [0.7029],\n",
       "        [0.6119],\n",
       "        [0.8774],\n",
       "        [0.9431],\n",
       "        [0.4124],\n",
       "        [0.4886],\n",
       "        [0.1877],\n",
       "        [0.4452],\n",
       "        [0.6262],\n",
       "        [0.9823],\n",
       "        [0.4635],\n",
       "        [0.9492],\n",
       "        [0.9028],\n",
       "        [0.9343],\n",
       "        [0.1275],\n",
       "        [0.8636],\n",
       "        [0.9394],\n",
       "        [0.5707],\n",
       "        [0.9896],\n",
       "        [0.8516],\n",
       "        [0.6589],\n",
       "        [0.1427],\n",
       "        [0.3436],\n",
       "        [0.4723],\n",
       "        [0.9791],\n",
       "        [0.8443],\n",
       "        [0.9746],\n",
       "        [0.3082],\n",
       "        [0.9398],\n",
       "        [0.9888],\n",
       "        [0.7867],\n",
       "        [0.5611],\n",
       "        [0.6133],\n",
       "        [0.2216],\n",
       "        [0.7310],\n",
       "        [0.8226],\n",
       "        [0.4127],\n",
       "        [0.7344],\n",
       "        [0.9775],\n",
       "        [0.8927],\n",
       "        [0.9902],\n",
       "        [0.9819],\n",
       "        [0.7064],\n",
       "        [0.9727],\n",
       "        [0.7107],\n",
       "        [0.9194],\n",
       "        [0.5488],\n",
       "        [0.9287],\n",
       "        [0.1849],\n",
       "        [0.9170],\n",
       "        [0.8172],\n",
       "        [0.4231],\n",
       "        [0.8697],\n",
       "        [0.3881],\n",
       "        [0.2399],\n",
       "        [0.4931],\n",
       "        [0.8016],\n",
       "        [0.5586],\n",
       "        [0.9276],\n",
       "        [0.9831],\n",
       "        [0.7249],\n",
       "        [0.2405],\n",
       "        [0.4668],\n",
       "        [0.5413]], device='cuda:0', grad_fn=<ClampBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値の補正を行う（ヒント部分）\n",
    "# Randomly set half of the confidences to 1 (i.e. no hints)\n",
    "b = Variable(torch.bernoulli(torch.Tensor(confidence.size()).uniform_(0, 1))).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confidence * b + (1 - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import encode_onehot\n",
    "labels = Variable(labels).cuda(async=True)\n",
    "labels_onehot = Variable(encode_onehot(labels, num_classes))\n",
    "# 予測を小さくして、正解ラベルの分布を足す\n",
    "pred_new = pred_original * conf.expand_as(pred_original) + labels_onehot * (1 - conf.expand_as(labels_onehot))\n",
    "pred_new = torch.log(pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失計算\n",
    "prediction_criterion = nn.NLLLoss().cuda()\n",
    "xentropy_loss = prediction_criterion(pred_new, labels)\n",
    "confidence_loss = torch.mean(-torch.log(confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takano/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "if 0.3 > confidence_loss.data[0]:\n",
    "    print('yy')\n",
    "else:\n",
    "    print('nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 損失を定義\n",
    "total_loss = xentropy_loss + (lmbda * confidence_loss)\n",
    "if budget > confidence_loss.data[0]:\n",
    "    lmbda = lmbda / 1.01\n",
    "elif budget <= confidence_loss.data[0]:\n",
    "    lmbda = lmbda / 0.99"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
