{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.losses import categorical_crossentropy, mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "num_labeled_images = 100\n",
    "features_dim = 4096\n",
    "num_classes = 10\n",
    "noise_dim = 100\n",
    "latent_dim = noise_dim\n",
    "batch_size=100\n",
    "steps_per_epoch = (60000 - num_labeled_images) // batch_size\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "optimizer = Adam(0.001, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "input_noise = Input(shape=(latent_dim,))\n",
    "\n",
    "# hidden layer\n",
    "g = Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim)(input_noise)\n",
    "g = Reshape((7, 7, 128))(g)\n",
    "g = BatchNormalization(momentum=0.8)(g)\n",
    "g = UpSampling2D()(g)\n",
    "g = Conv2D(128, kernel_size=3, padding=\"same\")(g)\n",
    "g = Activation(\"relu\")(g)\n",
    "g = BatchNormalization(momentum=0.8)(g)\n",
    "g = UpSampling2D()(g)\n",
    "g = Conv2D(64, kernel_size=3, padding=\"same\")(g)\n",
    "g = Activation(\"relu\")(g)\n",
    "g = BatchNormalization(momentum=0.8)(g)\n",
    "g = Conv2D(1, kernel_size=3, padding=\"same\")(g)\n",
    "\n",
    "# outputs\n",
    "g_image = Activation(\"tanh\")(g)\n",
    "\n",
    "generator = Model(input_noise, g_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "input_image = Input(shape=img_shape)\n",
    "\n",
    "d = Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\")(input_image)\n",
    "d = LeakyReLU(alpha=0.2)(d)\n",
    "d = Dropout(0.25)(d)\n",
    "d = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(d)\n",
    "d = ZeroPadding2D(padding=((0,1),(0,1)))(d)\n",
    "d = LeakyReLU(alpha=0.2)(d)\n",
    "d = Dropout(0.25)(d)\n",
    "d = BatchNormalization(momentum=0.8)(d)\n",
    "d = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(d)\n",
    "d = LeakyReLU(alpha=0.2)(d)\n",
    "d = Dropout(0.25)(d)\n",
    "d = BatchNormalization(momentum=0.8)(d)\n",
    "d = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(d)\n",
    "d = LeakyReLU(alpha=0.2)(d)\n",
    "d = Dropout(0.25)(d)\n",
    "features = Flatten(name='features_output')(d)\n",
    "\n",
    "label = Dense(num_classes, name='y_output')(features)\n",
    "# there is no activation here\n",
    "\n",
    "discriminator = Model(input_image, [features, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "validity = discriminator(g_image)\n",
    "combined = Model(input_noise, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#  Loss functions #\n",
    "##############\n",
    "\n",
    "def softmax_cross_entropy(y_true, y_output):\n",
    "    y_pred = K.softmax(y_output)\n",
    "    loss =categorical_crossentropy(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def discriminate_real(y_output, batch_size=batch_size):\n",
    "    # logD(x) = logZ(x) - log(Z(x) + 1)  where Z(x) = sum_{k=1}^K exp(l_k(x))\n",
    "    log_zx = K.logsumexp(y_output, axis=1)\n",
    "    log_dx = log_zx - K.softplus(log_zx)\n",
    "    dx = K.sum(K.exp(log_dx)) / batch_size\n",
    "    loss = -K.sum(log_dx) / batch_size\n",
    "    return loss, dx\n",
    "    \n",
    "def discriminate_fake(y_output, batch_size=batch_size):\n",
    "    # log{1 - D(x)} = log1 - log(Z(x) + 1)\n",
    "    log_zx_g = K.logsumexp(y_output, axis=1)\n",
    "    loss = K.sum(K.softplus(log_zx_g)) / batch_size\n",
    "    return loss\n",
    "\n",
    "#################\n",
    "#  Discriminator Loss #\n",
    "#################\n",
    "\n",
    "def labeled_loss(y_true, y_output):\n",
    "    class_loss = softmax_cross_entropy(y_true, y_output)\n",
    "    _,dx = discriminate_real(y_output, batch_size=batch_size)\n",
    "    return class_loss\n",
    "\n",
    "def unlabeled_loss(g_label, y_output, batch_size=batch_size):    \n",
    "    loss_real,dx = discriminate_real(y_output, batch_size=batch_size)\n",
    "    loss_fake = discriminate_fake(g_label, batch_size=batch_size)\n",
    "    return loss_real + loss_fake\n",
    "    \n",
    "###############\n",
    "#  Generator Loss #\n",
    "###############\n",
    "\n",
    "def feature_matching(features_true, features_fake):\n",
    "    return mean_squared_error(features_true, features_fake)\n",
    "\n",
    "def generator_loss(_, y_output):\n",
    "    loss_real,dx = discriminate_real(y_output, batch_size=batch_size)\n",
    "    return loss_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_model(discriminator, to_file='discriminator_model.png', show_shapes=True)\n",
    "plot_model(combined, to_file='combined_model.png', show_shapes=True)\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "# load_img('discriminator_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load_img('combined_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "num_samples = 10\n",
    "x_labeled = []\n",
    "y_labeled = []\n",
    "x_unlabeled = []\n",
    "\n",
    "for class_index in range(10):\n",
    "    label_index = np.where(y_train == class_index)\n",
    "    class_input_data = x_train[label_index]\n",
    "    \n",
    "    # labeled data\n",
    "    x_labeled.append(class_input_data[:num_samples])\n",
    "    y_labeled.append(np.full(num_samples, class_index, int))\n",
    "    \n",
    "    # unlabeled data\n",
    "    x_unlabeled.append(class_input_data[num_samples:])\n",
    "    \n",
    "x_labeled = np.concatenate(x_labeled, axis=0)\n",
    "x_unlabeled = np.concatenate(x_unlabeled, axis=0)\n",
    "x_labeled = x_labeled.astype('float32') / 255\n",
    "x_unlabeled = x_unlabeled.astype('float32') / 255\n",
    "\n",
    "x_labeled = x_labeled.reshape(x_labeled.shape+(1,))\n",
    "x_unlabeled = x_unlabeled.reshape(x_unlabeled.shape+(1,))\n",
    "\n",
    "y_labeled = np.concatenate(y_labeled, axis=0)\n",
    "y_labeled_onehot = np.eye(num_classes)[y_labeled]\n",
    "\n",
    "\n",
    "# test data\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape+(1,))\n",
    "y_test = np.eye(num_classes)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled input_shape: (100, 28, 28, 1), (100, 10)\n",
      "unlabeled input_shape: (59900, 28, 28, 1)\n",
      "test input_shape:  (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('labeled input_shape: {}, {}\\nunlabeled input_shape: {}'.format(x_labeled.shape, y_labeled_onehot.shape, x_unlabeled.shape))\n",
    "print('test input_shape: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59900,) (59900,)\n"
     ]
    }
   ],
   "source": [
    "# 教師なしの枚数が、教師ありと一致するようにリピート\n",
    "labeled_index = []\n",
    "for i in range(len(x_unlabeled) // len(x_labeled)):\n",
    "    l = np.arange(len(x_labeled))\n",
    "    np.random.shuffle(l)\n",
    "    labeled_index.append(l)\n",
    "    \n",
    "labeled_index = np.concatenate(labeled_index)\n",
    "unlabeled_index = np.arange(len(x_unlabeled))\n",
    "print(labeled_index.shape, unlabeled_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100\n",
      "step 1/599\n",
      "label_loss: 2.6410346031188965, label_acc: 0.07000000029802322\n"
     ]
    }
   ],
   "source": [
    "dummy_features = np.zeros((batch_size, features_dim))\n",
    "dummy_label = np.zeros((batch_size, num_classes))\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('epoch {}/{}'.format(epoch+1, epochs))\n",
    "    \n",
    "    np.random.shuffle(unlabeled_index)\n",
    "    np.random.shuffle(labeled_index)\n",
    "    \n",
    "    for step in range(steps_per_epoch):\n",
    "        print('step {}/{}'.format(step+1, steps_per_epoch))\n",
    "        unlabel_index_range = unlabeled_index[step*batch_size:(step+1)*batch_size]\n",
    "        label_index_range = labeled_index[step*batch_size:(step+1)*batch_size]\n",
    "        \n",
    "        images_l = x_labeled[label_index_range]\n",
    "        label_l = y_labeled_onehot[label_index_range]\n",
    "        images_u = x_unlabeled[unlabel_index_range]\n",
    "        \n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        \n",
    "        #########\n",
    "        # for label\n",
    "        #########\n",
    "        discriminator.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss= labeled_loss,\n",
    "            loss_weights={'features_output': 0., 'y_output': 1.},\n",
    "            metrics = {'y_output': 'accuracy'})\n",
    "        \n",
    "        # Train the discriminator\n",
    "        d_loss_label = discriminator.train_on_batch(images_l, [dummy_features, label_l])\n",
    "        print('label_loss: {}, label_acc: {}'.format(d_loss_label[0], d_loss_label[3]))\n",
    "        \n",
    "        ############\n",
    "        # for unlabeled\n",
    "        ############\n",
    "        discriminator.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss= unlabeled_loss,\n",
    "            loss_weights={'features_output': 0., 'y_output': 1.})\n",
    "        \n",
    "        z_batch = np.random.normal(0, 1, (batch_size, noise_dim)).astype(np.float32)\n",
    "        _, g_label = combined.predict(z_batch)\n",
    "        \n",
    "        # Train the discriminator\n",
    "        d_loss_unlabel = discriminator.train_on_batch(images_u, [dummy_features, g_label])\n",
    "        print('unlabel_loss : ', d_loss_unlabel[0])\n",
    "\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        \n",
    "        combined.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss= [feature_matching, generator_loss],\n",
    "            loss_weights=[1, 1])\n",
    "        \n",
    "        # Train the generator\n",
    "        z_batch = np.random.normal(0, 1, (batch_size, noise_dim)).astype(np.float32)\n",
    "        features_true, _ = discriminator.predict(images_l)\n",
    "        g_loss = combined.train_on_batch(z_batch, [features_true, dummy_label])\n",
    "\n",
    "        # Plot the progress\n",
    "        print ('g_loss', g_loss)\n",
    "    \n",
    "        # validation\n",
    "        discriminator.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss= labeled_loss,\n",
    "            loss_weights={'features_output': 0., 'y_output': 1.},\n",
    "            metrics = {'y_output': 'accuracy'})\n",
    "        \n",
    "        test_eval = discriminator.evaluate(x_test, [np.zeros((10000, features_dim)), y_test])\n",
    "        print('val_acc: ', test_eval[3])\n",
    "        history.append(test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
